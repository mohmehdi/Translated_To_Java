{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0dd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import List,Tuple,Dict\n",
    "from datetime import timedelta\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "# Define regex patterns for comments\n",
    "java_single_line_comment_regex = r\"\\/\\/.*\"\n",
    "java_multiline_comment_regex = r\"\\/\\*(?:[^*]|\\*(?!\\/))*\\*\\/\"\n",
    "kotlin_single_line_comment_regex = r\"\\/\\/.*\"\n",
    "kotlin_multiline_comment_regex = r\"\\/\\*[\\s\\S\\n]*?\\*\\/\"\n",
    "\n",
    "def clear_response(response:str)->str:\n",
    "    pattern = re.compile(r'\\b[p|P]ackage\\s+([\\w.]+)\\s*;')\n",
    "    start = 0\n",
    "    match = pattern.search(response)\n",
    "\n",
    "    if match:\n",
    "        start =  match.start()\n",
    "\n",
    "    return  response[start:response.rfind('}')+1]\n",
    "def find_last_brace(source_code: str) -> str:\n",
    "    # Find the last '}' character\n",
    "    last_brace_index = source_code.rfind('}')\n",
    "\n",
    "    return last_brace_index\n",
    "\n",
    "def remove_comments(content,file_type):\n",
    "    \"\"\"\n",
    "    Opens a Java or Kotlin file, removes comments, and saves the changes.\n",
    "    Args:\n",
    "        file_path: The path to the Java or Kotlin file.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Determine file type based on extension\n",
    "    if file_type == \"java\":\n",
    "        pattern = java_single_line_comment_regex + \"|\" + java_multiline_comment_regex\n",
    "    elif file_type == \"kotlin\":\n",
    "        pattern = kotlin_single_line_comment_regex + \"|\" + kotlin_multiline_comment_regex\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_type}\")\n",
    "\n",
    "    # Remove comments using regex\n",
    "    clean_content = re.sub(pattern, \"\", content, )\n",
    "    return clean_content\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str =  \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(\"gpt-3.5-turbo\")\n",
    "    # return len(tokenizer.tokenize(string))\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    if response.choices[0][\"finish_reason\"] == \"length\":\n",
    "        raise Exception(\"finish_reason == length\")\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def remove_markdown(text):\n",
    "    text = text.replace('```java','')\n",
    "    return text.replace('```','')\n",
    "#     code_regex = r\"java(.*?)\"\n",
    "#     match = re.search(code_regex,text, re.DOTALL)\n",
    "#     if match is not None:\n",
    "#         return match.group(1)\n",
    "#     else:\n",
    "#         return text\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def has_one_open_and_close_parenthesis(input_string):\n",
    "    open_count = input_string.count('(')\n",
    "    close_count = input_string.count(')')\n",
    "\n",
    "    if open_count == 1 and close_count == 1:\n",
    "        return input_string.find('(')\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def contains_forbidden_characters(input_string, forbidden_characters):\n",
    "    return not any(char in forbidden_characters for char in input_string)\n",
    "\n",
    "def clean_parameter_text(raw_params:str):\n",
    "\n",
    "    raw_params = raw_params.replace('\\n',' ')\n",
    "\n",
    "    o_chars = {'<','{','('}\n",
    "    c_chars = {'>','}',')'}\n",
    "    char_counter = 0\n",
    "    new_str=''\n",
    "    for i in range(len(raw_params)):\n",
    "        if raw_params[i]!=' ' or char_counter==0:\n",
    "            if raw_params[i]==',' and char_counter==0:\n",
    "                new_str+='|'\n",
    "            else:\n",
    "                new_str+=raw_params[i]\n",
    "\n",
    "        if raw_params[i] in o_chars:\n",
    "          char_counter+=1\n",
    "        if raw_params[i] in c_chars:\n",
    "          char_counter-=1\n",
    "    return '|'.join([s.strip() for s in new_str.split('|') if s.strip()!=''])\n",
    "\n",
    "\n",
    "def find_parentheses_indices(code: str, start_index: int, char = '()') -> tuple:\n",
    "    open_parentheses_count = 0\n",
    "    end_index = -1\n",
    "\n",
    "    for i in range(start_index, len(code)):\n",
    "        if code[i] == char[0]:\n",
    "            if open_parentheses_count == 0:\n",
    "                start_index = i\n",
    "            open_parentheses_count += 1\n",
    "        elif code[i] == char[1]:\n",
    "            open_parentheses_count -= 1\n",
    "            if open_parentheses_count == 0:\n",
    "                end_index = i\n",
    "                break\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "\n",
    "class Function:\n",
    "    def __init__(self, name: str = \"\", parameter_types: List[str] = None):\n",
    "        self.name = name\n",
    "\n",
    "        # Convert types to a base form\n",
    "        self.parameter_types = [Function.convert_primitive_type(t.strip().replace('?','')) for t in parameter_types] if parameter_types is not None else []\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_primitive_type(kotlin_type: str) -> str:\n",
    "        kotlin_to_java_primitive_mapping = {\n",
    "            'Int': 'int',\n",
    "            'Long': 'long',\n",
    "            'Short': 'short',\n",
    "            'Byte': 'byte',\n",
    "            'Double': 'double',\n",
    "            'Float': 'float',\n",
    "            'Char': 'char',\n",
    "            'Boolean': 'boolean',\n",
    "            'String': 'String',  # Add other types if necessary\n",
    "            'MutableSet':'Set',\n",
    "            'Any':'Object'\n",
    "        }\n",
    "        for k,v in kotlin_to_java_primitive_mapping.items():\n",
    "            kotlin_type = kotlin_type.replace(k,v)\n",
    "        return kotlin_type\n",
    "\n",
    "class KotlinParser:\n",
    "    @staticmethod\n",
    "    def get_classes(source_code: str) -> List[Function]:\n",
    "        class_pattern = re.compile(r'\\b(?:class|interface|enum class)\\s+(\\w+)')\n",
    "        functions = []\n",
    "\n",
    "        for match in class_pattern.finditer(source_code):\n",
    "            class_name = match.group(1)\n",
    "            functions.append(Function(name=class_name))\n",
    "\n",
    "        return functions\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_nullable_marker(param_type: str) -> str:\n",
    "        # Remove '?' from the parameter type\n",
    "        return param_type.replace('?','').strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_functions(source_code: str) -> List[Function]:\n",
    "        # Find all methods in the source code\n",
    "        method_pattern = re.compile(r'fun\\s+([\\w.]+)\\s*\\(')\n",
    "        matches = method_pattern.finditer(source_code)\n",
    "\n",
    "        functions = []\n",
    "        for match in matches:\n",
    "            method_name = match.group(1)\n",
    "            start_index = match.start()\n",
    "            start,end = find_parentheses_indices(source_code,start_index)\n",
    "            clean_params = clean_parameter_text(source_code[start+1:end])\n",
    "            types = [p.split(':')[1] for p in clean_params.split('|')] if clean_params!=\"\" else [\"\"]\n",
    "            functions.append(Function(name=method_name, parameter_types=types))\n",
    "        return functions\n",
    "\n",
    "\n",
    "\n",
    "class JavaParser:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_classes(source_code: str) -> List[Function]:\n",
    "        class_pattern = re.compile(r'\\b(?:class|interface|enum)\\s+(\\w+)')\n",
    "        functions = []\n",
    "\n",
    "        for match in class_pattern.finditer(source_code):\n",
    "            class_name = match.group(1)\n",
    "            functions.append(Function(name=class_name))\n",
    "\n",
    "        return functions\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_functions(source_code: str) -> List[Function]:\n",
    "        method_pattern = re.compile(r'\\b(?:public|private|protected|static|final|synchronized|abstract|native|strictfp)\\s+[^=;{]*({|;)')\n",
    "        matches = method_pattern.finditer(source_code)\n",
    "\n",
    "        functions = []\n",
    "        for match in matches:\n",
    "            block = match.group()\n",
    "            if '{' in block: # find method head / it ends with '{' or for interfaces end with ';' which is found by regex\n",
    "                block = block[:block.find('{')]\n",
    "            open_p = has_one_open_and_close_parenthesis(block)\n",
    "            if open_p != -1: # find the open parantesis '(' index\n",
    "                if contains_forbidden_characters(block[:open_p],set(['='])):\n",
    "                    method_name = block[:open_p].split()[-1]\n",
    "\n",
    "                    start_index = match.start()\n",
    "                    start_index = block.find(method_name)\n",
    "\n",
    "                    start,end = find_parentheses_indices(block,start_index)\n",
    "                    clean_params = clean_parameter_text(block[start+1:end])\n",
    "                    types = [p.split()[0] for p in clean_params.split('|')] if clean_params!=\"\" else [\"\"]\n",
    "                    functions.append(Function(name=method_name, parameter_types=types))\n",
    "        return functions\n",
    "\n",
    "\n",
    "\n",
    "class CompareFiles:\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_annotations(java_code: str) -> str:\n",
    "        # Remove all annotations\n",
    "        return re.sub(r'@\\w+\\s*', '', java_code)\n",
    "\n",
    "    @staticmethod\n",
    "    def check_package_declaration(kotlin_code: str,java_code: str) -> bool:\n",
    "        package_declaration_pattern = re.compile(r'^\\s*package\\s+(\\w+(\\.\\w+)*)\\s*$', re.MULTILINE)\n",
    "        match = package_declaration_pattern.search(kotlin_code)\n",
    "\n",
    "        if not match:\n",
    "          return False\n",
    "        package = match.group(0).strip()\n",
    "        return True if package in java_code else False\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def check_syntax_keywords(java_source: str) -> bool:\n",
    "        java_keywords = [\"fun\", \"val\", \"var\"]  # Add more keywords as needed\n",
    "\n",
    "        for keyword in java_keywords:\n",
    "            if re.search(r'\\b{}\\b'.format(keyword), java_source):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "    @staticmethod\n",
    "    def compare_classes(kotlin_classes, java_classes) -> Tuple[str,int]:\n",
    "        report = \"\"\n",
    "        score_counter = 0\n",
    "        common_classes = kotlin_classes.intersection(java_classes)\n",
    "        missing_in_java = kotlin_classes - common_classes\n",
    "        missing_in_kotlin = java_classes - common_classes\n",
    "\n",
    "        # print(\"Common Classes:\")\n",
    "        # for common_class in common_classes:\n",
    "        #     print(f\"+ {common_class}\")\n",
    "\n",
    "        if missing_in_java:\n",
    "            report+=\"\\n//Classes missing in Java:\\n\"\n",
    "            for missing_class in missing_in_java:\n",
    "                report+=f\"//- {missing_class}\\n\"\n",
    "                score_counter+=1\n",
    "\n",
    "        if missing_in_kotlin:\n",
    "            report+=\"\\n//Classes extra in Java:\\n\"\n",
    "            for missing_class in missing_in_kotlin:\n",
    "                report+=f\"//+ {missing_class}\\n\"\n",
    "                score_counter+=1\n",
    "        return report,score_counter\n",
    "\n",
    "    @staticmethod\n",
    "    def compare_functions(kotlin_functions: List[Function], java_functions: List[Function]) -> Tuple[str,int]:\n",
    "        report=\"\"\n",
    "        common_functions = []\n",
    "        missing_in_java = []\n",
    "        missing_in_kotlin = []\n",
    "        score_counter=0\n",
    "\n",
    "        # Compare functions by name and parameters\n",
    "        for kotlin_func in kotlin_functions:\n",
    "            matching_java_funcs = [java_func for java_func in java_functions if\n",
    "                                   java_func.name == kotlin_func.name and java_func.parameter_types == kotlin_func.parameter_types]\n",
    "\n",
    "            if matching_java_funcs:\n",
    "                common_functions.extend(matching_java_funcs)\n",
    "            else:\n",
    "                missing_in_java.append(kotlin_func)\n",
    "\n",
    "        # Find functions missing in Kotlin\n",
    "        missing_in_kotlin = [java_func for java_func in java_functions if java_func not in common_functions]\n",
    "\n",
    "        # print(\"\\n common Functions:\")\n",
    "        # for common_func in common_functions:\n",
    "        #     print(f\"+ {common_func.name}({', '.join(common_func.parameter_types)})\")\n",
    "\n",
    "        if missing_in_java:\n",
    "            report+=\"\\n//Functions missing in Java:\\n\"\n",
    "            for missing_func in missing_in_java:\n",
    "                report+=f\"//- {missing_func.name}({', '.join(missing_func.parameter_types)})\\n\"\n",
    "                score_counter+=1\n",
    "        if missing_in_kotlin:\n",
    "            report+=\"\\n//Functions extra in Java:\\n\"\n",
    "            for missing_func in missing_in_kotlin:\n",
    "                report+=f\"//+ {missing_func.name}({', '.join(missing_func.parameter_types)})\\n\"\n",
    "                score_counter+=1\n",
    "        return report,score_counter\n",
    "\n",
    "    @staticmethod\n",
    "    def compare(kotlin_source: str, java_source: str) -> Tuple[str,int]:\n",
    "        kotlin_parser = KotlinParser()\n",
    "        java_parser = JavaParser()\n",
    "\n",
    "        java_source = java_source[:java_source.rfind('}')+1]\n",
    "        java_source = CompareFiles.remove_annotations(java_source)\n",
    "\n",
    "        kotlin_classes = {cls.name for cls in kotlin_parser.get_classes(kotlin_source)}\n",
    "        java_classes = {cls.name for cls in java_parser.get_classes(java_source)}\n",
    "\n",
    "        kotlin_functions = kotlin_parser.get_functions(kotlin_source)\n",
    "        java_functions = java_parser.get_functions(java_source)\n",
    "\n",
    "        def find_parentheses_indices(code: str, char = '()') -> bool:\n",
    "            open_parentheses_count = 0\n",
    "            for i in range(len(code)):\n",
    "                if code[i] == char[0]:\n",
    "                    open_parentheses_count += 1\n",
    "                elif code[i] == char[1]:\n",
    "                    open_parentheses_count -= 1\n",
    "            if open_parentheses_count == 0:\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        syntax = find_parentheses_indices(java_source,'()')\n",
    "        syntax = syntax and find_parentheses_indices(java_source,'{}')\n",
    "\n",
    "        class_report , class_score = CompareFiles.compare_classes(kotlin_classes, java_classes)\n",
    "        fun_report,fun_score = CompareFiles.compare_functions(kotlin_functions, java_functions)\n",
    "        final_score =  class_score + fun_score + (0 if syntax else 100)\n",
    "\n",
    "\n",
    "        report = \"\\n//⚠!#!\" if final_score != 0 else \"\"\n",
    "        report += \"\\n//--------------------Class--------------------\"\n",
    "        report += class_report\n",
    "        report += \"\\n//-------------------Functions-----------------\"\n",
    "        report +=fun_report\n",
    "        report += \"\\n//-------------------Extra---------------------\"\n",
    "        report += \"\\n//Bracket problem\" if not syntax else \"\"\n",
    "        report += \"\\n//Found syntax problems\" if CompareFiles.check_syntax_keywords(java_source) else \"\"\n",
    "\n",
    "        if CompareFiles.check_package_declaration(kotlin_source,java_source)==False:\n",
    "            report += \"\\n//Issue with package decleration\"\n",
    "\n",
    "        report+=\"\\n//---------------------------------------------\"\n",
    "        return report,final_score\n",
    "# Example usage:\n",
    "kotlin_code = \"\"\"\n",
    "package java.test\n",
    "class A {\n",
    "\n",
    "\n",
    "    @Test\n",
    "    fun upvoteStory_whenUpvoteSuccessful() = runBlocking {\n",
    "        // Given that the use case responds with success\n",
    "        whenever(upvoteStory(storyId)).thenReturn(Result.Success(Unit))\n",
    "        // And the view model is constructed\n",
    "        val viewModel = withViewModel()\n",
    "        var result: Result<Unit>? = null\n",
    "\n",
    "        // When upvoting a story\n",
    "        viewModel.storyUpvoteRequested(storyId) { result = it }\n",
    "\n",
    "        // Then the result is successful\n",
    "        assertEquals(Result.Success(Unit), result)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fun methodA(param1: Int, param2: String) {\n",
    "        // Method body\n",
    "    }\n",
    "\n",
    "    fun method_A(){}\n",
    "\n",
    "    fun methodB() {\n",
    "        // Method body\n",
    "    }\n",
    "    fun anotation(drawerView : View?, slideOffset: Float) {\n",
    "        super.onDrawerSlide(drawerView, slideOffset);\n",
    "    }\n",
    "}\n",
    "\n",
    "class B {\n",
    "    fun onlyKotlin() {\n",
    "        // Method body\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "java_code = \"\"\"\n",
    "Package java.test;\n",
    "class A {\n",
    "\n",
    "\n",
    "    @Test\n",
    "    public void upvoteStory_whenUpvoteSuccessful() throws Exception {\n",
    "        whenever(upvoteStory.invoke(storyId)).thenReturn(Result.Success(null));\n",
    "\n",
    "        StoryViewModel viewModel = withViewModel();\n",
    "        Result<Object> result = null;\n",
    "\n",
    "        viewModel.storyUpvoteRequested(storyId, (r) -> result = r);\n",
    "\n",
    "        Assert.assertEquals(Result.Success(null), result);\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    public void methodA(int param1,\n",
    "        String    param2) {\n",
    "        // Method body\n",
    "    }\n",
    "    public static void methodB(){}\n",
    "    private void method_A(){}\n",
    "\n",
    "    public void onlyJava() {\n",
    "        // Method body\n",
    "    }\n",
    "        public void anotation(@NonNull View drawerView, float slideOffset) {\n",
    "        super.onDrawerSlide(drawerView, slideOffset);\n",
    "    }\n",
    "\n",
    "    @Test\n",
    "    public void clickOnAndroidHomeIcon_OpensAndClosesNavigation() {\n",
    "        Espresso.onView(withId(R.id.drawer_layout))\n",
    "                .check(matches(DrawerMatchers.isClosed(Gravity.START)));\n",
    "\n",
    "        clickOnHomeIconToOpenNavigationDrawer();\n",
    "        checkDrawerIsOpen();\n",
    "    }\n",
    "}\n",
    "\n",
    "class C {\n",
    "    fun methodC() {\n",
    "        // Method body\n",
    "    }\n",
    "Note: The `@Suppress(\"UNCHECKED_CAST\")` class annotation in the Kotlin code is not needed in Java because the `create` method in the `ViewModelProvider.Factory` interface already has a generic type parameter `<T extends ViewModel>`.</s>\n",
    "\"\"\"\n",
    "\n",
    "# Comparing Kotlin and Java files\n",
    "report,score = CompareFiles.compare(kotlin_code, java_code)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec084f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'leakcanary_Diff'\n",
    "merged_url = f'https://raw.githubusercontent.com/benymaxparsa/Kotlin_projects_commit_diff/main/{proj_name}-merged.txt'\n",
    "paths_url = f'https://raw.githubusercontent.com/benymaxparsa/Kotlin_projects_commit_diff/main/{proj_name}-paths.txt'\n",
    "dir_name = merged_url.split('/')[4]\n",
    "print(dir_name)\n",
    "print(paths_url)\n",
    "\n",
    "r = requests.get(merged_url, allow_redirects=True)\n",
    "open('merged.txt', 'wb').write(r.content)\n",
    "\n",
    "with open('merged.txt','r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "scripts = content.split('<code block>')\n",
    "print(f\"code blocks: {len(scripts)}\")\n",
    "# print(scripts[0].strip())\n",
    "\n",
    "\n",
    "r = requests.get(paths_url, allow_redirects=True)\n",
    "open('paths.txt', 'wb').write(r.content)\n",
    "\n",
    "with open('paths.txt','r') as file:\n",
    "    paths = file.readlines()\n",
    "\n",
    "print(f\"files: {len(paths)}\")\n",
    "\n",
    "\n",
    "# rename .kt to .java\n",
    "new_paths = []\n",
    "for i in range(len(paths)):\n",
    "    new_paths.append(''.join(paths[i].strip().split('.')[:-1]) + '.java')\n",
    "print(new_paths[0])\n",
    "len(new_paths)\n",
    "\n",
    "def get_file_name(index):\n",
    "    return new_paths[index]\n",
    "\n",
    "begin_dico = dict()\n",
    "end_dico = dict()\n",
    "def get_commit(path):\n",
    "    return path.split('/')[2].split('-')[-1]\n",
    "\n",
    "commits = [get_commit(c) for c in paths]\n",
    "unique = set(commits)\n",
    "for u in unique:\n",
    "    begin_dico[u] = commits.index(u)\n",
    "    end_dico[u] = len(commits) - commits[::-1].index(u)\n",
    "\n",
    "longest = max(scripts, key = lambda x:len(x))\n",
    "print(f\"Longest files has << {num_tokens_from_string(longest)} >> tokens\")\n",
    "\n",
    "\n",
    "incomplete_files = []\n",
    "translation_report =[]\n",
    "def translate(files_index:List[int],commit_words=None,index_to_commit={},translate_all = True):\n",
    "    result = []\n",
    "    skipped = 0\n",
    "    for i in tqdm(files_index):\n",
    "        code = scripts[i]\n",
    "        index = i\n",
    "        prev_response = \"\"\n",
    "        prev_score=-1\n",
    "        text = code.strip()\n",
    "        kotlin_classes = KotlinParser.get_classes(text)\n",
    "        \n",
    "        list_of_classes = None\n",
    "        if commit_words != None:\n",
    "            for data_tuple in commit_words:\n",
    "                # Check if the first element of the tuple starts with the desired string\n",
    "                if data_tuple[0].startswith(index_to_commit[i]):\n",
    "                    list_of_classes = data_tuple[1]\n",
    "        \n",
    "        if not translate_all:\n",
    "            list_of_classes = set(list_of_classes) - { 'changed',\n",
    " 'class',\n",
    " 'classes',\n",
    " 'close',\n",
    " 'from',\n",
    " 'in',\n",
    " 'with',\n",
    " 'is',\n",
    " 'of',\n",
    " 'open',\n",
    " 'to'}\n",
    "            if (new_paths[index].split('/')[-1].split('.')[0] not in list_of_classes) and (not set([k.name for k in kotlin_classes]) & list_of_classes):\n",
    "                skipped += 1\n",
    "                translation_report.append(new_paths[index].split('/')[-1].split('.')[0])\n",
    "                continue\n",
    "#         print(f\"Not Skipped: {new_paths[index].split('/')[-1].split('.')[0]}\")\n",
    "        prompts =[\n",
    "        f\"\"\"Translate the given Kotlin code to Java, adhering to the following constraints:\n",
    "{'In case functions  outside class exist in kotlin, put the translated java functions in a class using name of the file which is:' + new_paths[index].split('/')[-1].replace(\".java\",\"\") if len(kotlin_classes)==0 else \"\"}\n",
    "Preserve the original names of classes, fields, and methods without renaming.\n",
    "Translate the entire class, including all its fields, methods, inner classes, etc.\n",
    "Do not create any new classes, methods, or fields.\n",
    "Make no assumptions about the code, meaning not helper classes or functions.\n",
    "Keep the translation as close as possible to the original code.\n",
    "Under no circumstances add new classes, methods, or fields beyond what's in the original.\n",
    "Do not add new methods even if the reference is not available.\n",
    "Here's the original code block:\"\"\",]\n",
    "        for p in prompts:\n",
    "            prompt = f\"\"\"{p}\n",
    "```{text}```\"\"\"\n",
    "            orginal_source_tokens = num_tokens_from_string(text)\n",
    "            # max_tokens = (2*orginal_source_tokens) + int(extra_tokens_percentage*orginal_source_tokens) + extra_tokens\n",
    "\n",
    "            time.sleep(5)  # Delay for 5 seconds\n",
    "            try:\n",
    "                response = get_completion(prompt)\n",
    "                report,score = CompareFiles.compare(text, response)\n",
    "                if prev_score == -1 or score < prev_score:\n",
    "                    prev_score = score\n",
    "                    prev_response = report + '\\n' +clear_response(response)\n",
    "            except Exception as e:\n",
    "                if 'exceeded quota for this month' in str(e): # using the actual exception from the API did not work\n",
    "                    raise Exception(f'exceeded quota for this month, till this index:{index}')\n",
    "                response = f\"File: {get_file_name(index)}\\n⚠ Error: {e}\"\n",
    "                incomplete_files.append(get_file_name(index))\n",
    "                report,score = CompareFiles.compare(text, response)\n",
    "                if prev_score == -1 or score < prev_score:\n",
    "                    prev_score = score\n",
    "                    prev_response = report + '\\n' +response\n",
    "                # print(response)\n",
    "\n",
    "            report,score = CompareFiles.compare(text, response)\n",
    "            if prev_score == -1 or score < prev_score:\n",
    "                prev_score = score\n",
    "                prev_response = report + '\\n' +clear_response(response)\n",
    "            # print(f\"\\nTranslation score: {score}\")\n",
    "\n",
    "\n",
    "            if score==0 :\n",
    "                break\n",
    "\n",
    "        # if prev_score != 0 :\n",
    "        #     incomplete_files.append(get_file_name(index))\n",
    "\n",
    "        result.append([remove_markdown(prev_response),index])\n",
    "    print(f\"skipped: {skipped}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def save_files(result):\n",
    "    files = [[r[0],new_paths[r[1]]] for r in result]\n",
    "    files_index = [r[1] for r in result]\n",
    "    print(len(files))\n",
    "    for file in files:\n",
    "        path = os.path.dirname(file[1])\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        with open(file[1].strip(),'w') as f:\n",
    "            f.write(file[0])\n",
    "    shutil.make_archive(f'GPT-{proj_name}-{files_index[0]}-{files_index[-1]}', 'zip', dir_name)\n",
    "    shutil.rmtree(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def remove_between_parentheses(input_string):\n",
    "    return re.sub(r'\\([^)]*\\)', '', input_string)\n",
    "\n",
    "# Function to download JSON file from URL\n",
    "def download_json(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Failed to download JSON file\")\n",
    "\n",
    "# Function to extract description values and split them\n",
    "commit_words = []\n",
    "def extract_descriptions(data):\n",
    "    for item in data:\n",
    "        descriptions = []\n",
    "        commit = item.get(\"sha1\", '')\n",
    "        refactorings = item.get(\"refactorings\", [])\n",
    "        for refactoring in refactorings:\n",
    "            description = refactoring.get(\"description\", \"\")\n",
    "            if description:\n",
    "                description = remove_between_parentheses(description)\n",
    "                description = description.replace(\".\", \" \")\n",
    "                description = description.replace(\",\", \" \")\n",
    "                descriptions.extend(description.split())\n",
    "                # descriptions.extend(description.split(\" \"))\n",
    "\n",
    "        commit_words.append((commit,descriptions))\n",
    "\n",
    "\n",
    "# URL of the JSON file\n",
    "# Sunflower\n",
    "# json_url = \"https://drive.google.com/uc?export=download&id=1h1ZuljIs3sThLo31Nm2pkwOCBrz3uHLI\"\n",
    "# LeakCanary\n",
    "json_url = \"https://drive.google.com/uc?export=download&id=13lmA4E-bvVeqkt6gs7BCnCg9JpnsfogP\"\n",
    "\n",
    "# Download JSON file\n",
    "json_data = download_json(json_url)\n",
    "\n",
    "# Extract descriptions\n",
    "extract_descriptions(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = [\"297fa598\",\n",
    "          ]\n",
    "chunk_size = 30\n",
    "print(f\"calculating files for each chunk of size {chunk_size}\")\n",
    "\n",
    "\n",
    "all_files_index = [] \n",
    "for commit in commits:\n",
    "    all_files_index+=list(range(begin_dico[commit],end_dico[commit]))\n",
    "print(len(all_files_index))\n",
    "\n",
    "for i in range(0,len(all_files_index),chunk_size):\n",
    "    print(all_files_index[i:i+chunk_size])\n",
    "# for i in all_files_index:\n",
    "#     print(new_paths[i])\n",
    "\n",
    "print(\"\\ncalculating index to commit dict\")\n",
    "\n",
    "index_to_commit = {}\n",
    "for commit in commits:\n",
    "    commit_indices= list(range(begin_dico[commit],end_dico[commit]))\n",
    "    for i in commit_indices:\n",
    "        index_to_commit[i]=commit\n",
    "# index_to_commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ddc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_files = []\n",
    "for i in range(0,len(all_files_index),chunk_size):\n",
    "    result = translate(all_files_index[i:i+chunk_size],commit_words,index_to_commit,translate_all=False)\n",
    "    save_files(result)\n",
    "\n",
    "print(f\"{len(incomplete_files)} files are bad\")\n",
    "\n",
    "print(\"\\nSkipped Files:\")\n",
    "for skipped_file in translation_report:\n",
    "    print(skipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd47b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_classes = None\n",
    "if commit_words != None:\n",
    "    for data_tuple in commit_words:\n",
    "        # Check if the first element of the tuple starts with the desired string\n",
    "        if data_tuple[0].startswith(\"297f\"):\n",
    "            list_of_classes = data_tuple[1]\n",
    "set(list_of_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
